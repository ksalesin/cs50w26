<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title></title>
    <link rel="stylesheet" href="/~ksalesin/cs50/styles.css">
    <link rel="stylesheet" href="/~ksalesin/cs50/github-markdown.css">
</head>
<body>
    <div class="markdown-body nav">
        <h3><a href="/~ksalesin/cs50/" id="cs50">CS 50: Software Design and Implementation</a></h3>
        <ul>
            <li><a href="/~ksalesin/cs50/syllabus.html">Syllabus</a></li>
            <li><a href="/~ksalesin/cs50/schedule.html">Schedule</a></li>
            <li><a href="/~ksalesin/cs50/style.html">Style Guide</a></li>
            <li><a href="/~ksalesin/cs50/resources.html">Resources</a></li>
            <!-- <li><a href="/submit.html">Submit</a></li> -->
            <li id="knowledge-base"><a href="http://plink.cs.dartmouth.edu:3000/" target="_blank">Knowledge Base</a></li>
        </ul>
    </div>
    <div class="markdown-body content">
        <p>In this lab you'll continue the Tiny Search Engine (TSE) by coding the <em>Indexer</em> and a test program that saves and loads index files, according to the specs in this directory:</p>
<ul>
<li><a href="REQUIREMENTS.md">Requirements Spec</a></li>
<li><a href="DESIGN.md">Design Spec</a></li>
</ul>
<p>You will also write the Implementation Spec.</p>
<p>Grading will focus on <a href="https://github.com/CS50DartmouthFA2025/home/blob/main/logistics/style.md">CS50 coding style</a> - including consistent formatting, selection of identifier names, and use of meaningful comments - in addition to correctness, testing, and documentation.</p>
<p><em><strong>Your C code must compile without producing any compiler warnings.</strong></em>  You will lose points if the compiler produces warnings when using our CS50-standard compiler flags.</p>
<p><em><strong>If your submitted code fails to compile, or triggers a segmentation fault,</strong></em> you will fail some or all of our correctness tests.
Write defensive code: each function should check its pointer parameters for NULL, and take some appropriate (safe) action.
Write solid unit tests, test drivers, and use regression testing as your development proceeds.</p>
<p>If your submitted version has <em>known bugs</em>, that is, cases where it fails your own test cases, <em>and you describe those cases in your README file</em>, we will halve the number of points you lose for those cases.
In short, it is far better for you to demonstrate you <em>know</em> about the bug than to submit and hope we won't find it.</p>
<p><em><strong>Valgrind should report no memory errors or memory leaks, when crawler exits normally.</strong></em>
You will lose points for memory errors and leaks reported by valgrind on our tests.</p>
<h2>Preparation</h2>
<ol>
<li>Start with the same repository you used for Lab 4.
<em>Before you begin</em>, make sure you submitted Lab 4 correctly, <a href="https://github.com/CS50DartmouthFA2025/home/blob/main/logistics/submit.md">as instructed</a>.</li>
<li>Check to ensure your local repo is clean with <code>make clean</code> and everything looks correct according to <code>git status</code>.
<strong>Do not proceed</strong> if you have uncommitted changes or unpushed commits.
Seek help if you need to sort out your repo or GitHub.</li>
<li>Ensure you are again working on the <code>main</code> branch <strong>and</strong> that the <code>main</code> branch is up to date if you made any changes on <code>submit4</code> after branching off <code>main</code>.</li>
<li>Create a new subdirectory <code>indexer</code>.</li>
<li>Review Section 4 in <em><a href="https://github.com/CS50DartmouthFA2025/home/blob/main/knowledge/units/media/searchingtheweb.pdf">Searching the Web</a></em>, the paper about search engines.</li>
</ol>
<h2>Assignment</h2>
<p>:point_right:
Design and code the second subsystem of the Tiny Search Engine, the <em>Indexer</em>.
Your implementation must follow the <a href="REQUIREMENTS.md">Requirements Spec</a> and <a href="DESIGN.md">Design Spec</a>, and make good use of our abstract data structures.</p>
<p><strong>In the top directory,</strong></p>
<ol>
<li>Uncomment the commands for indexer, so <code>make</code> and <code>make clean</code> work to build (or clean) the libraries, crawler, and indexer.</li>
</ol>
<p><strong>In the <code>indexer</code> subdirectory,</strong></p>
<ol>
<li>Add a file <code>IMPLEMENTATION.md</code> to provide the Implementation Spec for <em>indexer</em> (not for index tester) and the testing plan for <em>indexer</em>.</li>
<li>Add a file <code>README.md</code> to describe any assumptions you made while writing the indexer, any ways in which your implementation differs from the Specs, or any ways in which you know your implementation fails to work.</li>
<li>Write a program <code>indexer.c</code> according to the Specs.</li>
<li>Write a program <code>indextest.c</code> according to the Specs.</li>
<li>Write a <code>Makefile</code> that will, by default, build the <code>indexer</code> and <code>indextest</code> executable programs.</li>
<li>Add a <code>make clean</code> target that removes files produced by Make or your tests.</li>
<li>Add a <code>make test</code> target that tests your indexer.</li>
<li>Write a <code>testing.sh</code> bash script that can be run by <code>make test</code>.
This script must include good comments describing your tests.
For best results, <code>make test</code> should run <code>bash -v testing.sh</code>.</li>
<li>Save the output of your tests with <code>make test &amp;&gt; testing.out</code>.</li>
<li>Add a <code>.gitignore</code> file telling Git to ignore the binary files (like <code>indexer</code> and <code>indextest</code>) and other unnecessary files in this directory.</li>
</ol>
<p><strong>In the <code>common</code> subdirectory,</strong></p>
<ol>
<li>Extend a module <code>pagedir.c</code> (common to the Crawler, Indexer, and Querier) to support any new operations on pageDirectories.</li>
<li>Add a module <code>index.c</code> (common between the Indexer, Querier, and indextest) to support saving and loading index files.</li>
<li>Add a module <code>word.c</code> (common between the Indexer and Querier) that implements <code>normalizeWord</code>.</li>
<li>Extend <code>Makefile</code> to include all three modules in <code>common.a</code>.</li>
</ol>
<h3>Submission</h3>
<p>Add/commit all the code and ancillary files required to build and test your solution; at a minimum your <strong>indexer</strong> directory should include the following files:
<code>.gitignore README.md IMPLEMENTATION.md Makefile indexer.c indextest.c testing.sh testing.out</code>
and your <strong>common</strong> directory should contain the following files:
<code>Makefile index.h index.c pagedir.h pagedir.c word.h word.c</code></p>
<p><em>Do not commit any data files produced by the crawler or indexer, any binary/object files produced by the compiler, backup files, core dumps, etc.</em></p>
<p>If you finish Lab 5 early, we encourage you to begin work on Lab 6.
Your Lab 5 submission may contain a partly-completed querier; the graders will ignore those files, but must be able to build your libraries and programs <em>from the top-level directory</em> without compilation errors and test your indexer without run-time errors.</p>
<p>To submit, read the <a href="https://github.com/CS50DartmouthFA2025/home/blob/main/logistics/submit.md">Lab submission instructions</a>.</p>
<h2>Hints and tips</h2>
<p>Many of the <a href="../crawler/README.md">Lab4 hints</a> are still relevant, and there are more tips in the <a href="https://github.com/CS50DartmouthFA2025/home/blob/main/knowledge/units/indexer.md">knowledge unit</a>.</p>
<h3>Testing</h3>
<p>If your crawler never quite worked, never fear!
You do not need a working crawler to write or test your indexer.
Try your indexer on our crawler's output, which we provide in <code>~/cs50-dev/shared/tse/output</code>.
Our indexer's output is in that same directory.</p>
<p>It can be tricky to compare two index files for equivalence - because the lines of an index file can be in any order, and the docIDs within a line can be in any order - so a simple run of <code>diff</code> won't always be sufficient.
Try using our <code>indexcmp</code> program; you can run it directly from the shared copy we installed:</p>
<pre><code class="language-bash">$ ~/cs50-dev/shared/tse/indexcmp
usage: ~/cs50-dev/shared/tse/indexcmp indexFilenameA indexFilenameB
</code></pre>
<p>It takes two arguments, each a pathname to an index file; it will print out any apparent differences.</p>
<h3>Hashtable</h3>
<p>&quot;How big should the hashtable be?&quot;</p>
<p>In the indexer/querier, we use a hashtable to store an inverted index (words –&gt; documents), and thus the hashtable is keyed by words.
The answer to the above question, then, depends on how many words will be in the index.</p>
<p>When building the inverted index, it's impossible to know in advance how many words you will find in all those pages encountered by the crawler.
Pick a reasonable size, perhaps something in the range of 200..900 slots.</p>
<p>When loading an inverted index from a file, though, you <em>can</em> know how many words... because there is one word per line in the index file, and it's easy to count the number of lines (see <code>file.h</code>).
Once your code can obtain the number of words, think about how it can compute a good size for your hashtable.</p>
<h3>pageDirectory</h3>
<p>The pageDirectory stores pages fetched and saved by the Crawler.
In Lab 4 you wrote functions <code>pagedir_init</code> (to mark a directory as a Crawler directory) and <code>pagedir_save</code> (to save a page into a file in that directory).
You may now need to write functions like <code>pagedir_validate(dir)</code> to verify whether <code>dir</code> is indeed a Crawler-produced directory,
and <code>pagedir_load</code> to load a page from a file in that directory.
Detail these (or other) functions in your Implementation spec.</p>
<h3>Index</h3>
<p>We strongly recommend you add an <code>index</code> module to the <code>common</code> library – a module to implement an abstract <code>index_t</code> type that represents an index in memory, and supports functions like <code>index_new()</code>, <code>index_delete()</code>, <code>index_save()</code>, and so forth.
Tip: much of it is a wrapper for a hashtable.</p>
<p>To write the index file, use the <code>_iterate</code> methods built into your data structures.
(Indeed you may need to have iterators call iterators!)
Do <em>not</em> use your <code>_print</code> methods for this purpose; those methods are meant for producing pretty human-readable output for debugging purposes.</p>
<p>To read each line of the index file, it works well to read the word, then loop calling <code>fscanf</code> with format <code>&quot;%d %d &quot;</code> to pull off one pair at a time, checking the return value of <code>fscanf</code>.
The specs allow your code to be optimistic about index files being in the correct format.</p>
<p>The functions found in <code>file.h</code> should be helpful.</p>
<h3>Makefile</h3>
<p>Your <code>indexer/Makefile</code> needs to build both <code>indexer</code> and <code>indextest</code> by default.
We recommend you add a phony top-most target:</p>
<pre><code class="language-make">all: indexer indextest
</code></pre>
<p>so that <code>make</code> or <code>make all</code> will build both programs; if you want to build just one, run <code>make indexer</code> or <code>make indextest</code>.</p>

    </div>
</body>
</html>